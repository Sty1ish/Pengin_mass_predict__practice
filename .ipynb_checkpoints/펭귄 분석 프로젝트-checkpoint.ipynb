{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71a826fe-35b9-426d-8b45-be3bdf87d41e",
   "metadata": {},
   "source": [
    "# EDA + 데이터 파악 파트\n",
    "\n",
    "## R에서 전반적인 EDA를 실시하였음.\n",
    "\n",
    "특이점이나 데이터의 분포, 그래프는 R 마크다운 파일을 참조하면 좋고\n",
    "아래 코드는 파이썬에서 파악한 결측값과 요약 통계을 표시한다.\n",
    "\n",
    "## 기초 모듈 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "572aec8f-7f7d-46eb-b901-8e69e8319c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f9a77d-4f48-4d85-a2c1-23b9417cdf89",
   "metadata": {},
   "source": [
    "## 데이터셋 임포트, 데이터 체크\n",
    "데이터의 형태는 아래와 같이 구성되어진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e28c874f-bb20-4949-9b4d-94216d75752d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 114 entries, 0 to 113\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   id                   114 non-null    int64  \n",
      " 1   Species              114 non-null    object \n",
      " 2   Island               114 non-null    object \n",
      " 3   Clutch Completion    114 non-null    object \n",
      " 4   Culmen Length (mm)   114 non-null    float64\n",
      " 5   Culmen Depth (mm)    114 non-null    float64\n",
      " 6   Flipper Length (mm)  114 non-null    int64  \n",
      " 7   Sex                  111 non-null    object \n",
      " 8   Delta 15 N (o/oo)    111 non-null    float64\n",
      " 9   Delta 13 C (o/oo)    111 non-null    float64\n",
      " 10  Body Mass (g)        114 non-null    int64  \n",
      "dtypes: float64(4), int64(3), object(4)\n",
      "memory usage: 9.9+ KB\n"
     ]
    }
   ],
   "source": [
    "os.chdir(r'C:\\Users\\styli\\Desktop\\데이콘 프로젝트\\동아리 pj-펭귄\\dataset')\n",
    "train = pd.read_csv('train.csv')\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e24b6fe-969e-4f3a-82e8-1c4f20235989",
   "metadata": {},
   "source": [
    "read_csv로 불러온 경우 무의미한 id행이 포함되어 있다. id행을 제거한다.\n",
    "또한 결측값이 존재하는 행이 존재함을 확인하였다.\n",
    "\n",
    ".info() 의 결과 행의 개수와 non-null의 개수가 다름을 통해 빠르게 파악 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78b7bdbd-67e1-4bf3-bf5f-3f15810d3069",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(\"id\",axis=1)\n",
    "# 결측값 있는 열 값 확인\n",
    "nacell = train[train.isna().sum(axis=1) > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a21a517-6b5e-40fe-b460-379047f593b4",
   "metadata": {},
   "source": [
    "팀의 EDA결과, -> EDA R로 한 파일에도 존재함. Rmd 파일을 참고하자.\n",
    "결측값이 등장하는 범주의 통계량은 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "734a5856-8e50-4626-9d5b-1269d5789050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count      111\n",
      "unique       2\n",
      "top       MALE\n",
      "freq        56\n",
      "Name: Sex, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train.loc[:,'Sex'].describe())\n",
    "# print(train.loc[:,'Sex'].value_counts())\n",
    "# Sex의 최빈은 MAlE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed9d741f-2fb2-470e-ba65-38d637c3da18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    111.000000\n",
      "mean       8.737634\n",
      "std        0.567698\n",
      "min        7.632200\n",
      "25%        8.272585\n",
      "50%        8.632590\n",
      "75%        9.264635\n",
      "max       10.025440\n",
      "Name: Delta 15 N (o/oo), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train.loc[:,'Delta 15 N (o/oo)'].describe())\n",
    "# delta 15의 평균은 8.73.... 해당연산값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abb792a1-a961-4fb4-b3b4-dea9e8ec2dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    111.000000\n",
      "mean     -25.723051\n",
      "std        0.859786\n",
      "min      -27.018540\n",
      "25%      -26.434025\n",
      "50%      -25.955410\n",
      "75%      -25.005945\n",
      "max      -24.102550\n",
      "Name: Delta 13 C (o/oo), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train.loc[:,'Delta 13 C (o/oo)'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52d5da4-18ac-4857-9e1b-72ac619ad935",
   "metadata": {},
   "source": [
    "먼저 결측값은 평균으로 처리하였다.\n",
    "train셋의 평균값으로, train셋, test셋에게 동등한 처리를 진행하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c5b33e2-144c-496a-b239-18802a2ac968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 114 entries, 0 to 113\n",
      "Data columns (total 10 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Species              114 non-null    object \n",
      " 1   Island               114 non-null    object \n",
      " 2   Clutch Completion    114 non-null    object \n",
      " 3   Culmen Length (mm)   114 non-null    float64\n",
      " 4   Culmen Depth (mm)    114 non-null    float64\n",
      " 5   Flipper Length (mm)  114 non-null    int64  \n",
      " 6   Sex                  111 non-null    object \n",
      " 7   Delta 15 N (o/oo)    114 non-null    float64\n",
      " 8   Delta 13 C (o/oo)    114 non-null    float64\n",
      " 9   Body Mass (g)        114 non-null    int64  \n",
      "dtypes: float64(4), int64(2), object(4)\n",
      "memory usage: 9.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# 결측값 처리\n",
    "\n",
    "train.loc[:,'Delta 15 N (o/oo)'] = train.loc[:,'Delta 15 N (o/oo)'].fillna(train.loc[:,'Delta 15 N (o/oo)'].mean())\n",
    "train.loc[:,'Delta 13 C (o/oo)'] = train.loc[:,'Delta 13 C (o/oo)'].fillna(train.loc[:,'Delta 13 C (o/oo)'].mean())\n",
    "# train[train.isna().sum(axis=1) > 0]\n",
    "train.info() # 결측값 더이상 없음 확인 -> rangeidx 114 = 모든 요소 114 non-null으로 확인됨."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d6ec94-0557-4a43-8fc5-fbb7b3367314",
   "metadata": {},
   "source": [
    "또한 테스트에서 사용할 test셋도 임포트 후 준비시켜 준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f54f90f-a203-4b78-8ff5-e6ea54c80e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 228 entries, 0 to 227\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Species              228 non-null    object \n",
      " 1   Island               228 non-null    object \n",
      " 2   Clutch Completion    228 non-null    object \n",
      " 3   Culmen Length (mm)   228 non-null    float64\n",
      " 4   Culmen Depth (mm)    228 non-null    float64\n",
      " 5   Flipper Length (mm)  228 non-null    float64\n",
      " 6   Sex                  222 non-null    object \n",
      " 7   Delta 15 N (o/oo)    219 non-null    float64\n",
      " 8   Delta 13 C (o/oo)    220 non-null    float64\n",
      "dtypes: float64(5), object(4)\n",
      "memory usage: 16.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋 미리 확인.\n",
    "test = pd.read_csv('test.csv')\n",
    "test = test.drop(\"id\",axis=1)\n",
    "\n",
    "test.info()\n",
    "# test에서도, sex, delta15, delta 13에서만 결측 발생중. id행 무쓸모 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3a22688-8aba-478a-a6d9-437d9200a270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 228 entries, 0 to 227\n",
      "Data columns (total 9 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Species              228 non-null    object \n",
      " 1   Island               228 non-null    object \n",
      " 2   Clutch Completion    228 non-null    object \n",
      " 3   Culmen Length (mm)   228 non-null    float64\n",
      " 4   Culmen Depth (mm)    228 non-null    float64\n",
      " 5   Flipper Length (mm)  228 non-null    float64\n",
      " 6   Sex                  222 non-null    object \n",
      " 7   Delta 15 N (o/oo)    228 non-null    float64\n",
      " 8   Delta 13 C (o/oo)    228 non-null    float64\n",
      "dtypes: float64(5), object(4)\n",
      "memory usage: 16.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# 결측값 처리-test셋은 train셋 값으로 동일하게 실시\n",
    "\n",
    "test.loc[:,'Delta 15 N (o/oo)'] = test.loc[:,'Delta 15 N (o/oo)'].fillna(train.loc[:,'Delta 15 N (o/oo)'].mean())\n",
    "test.loc[:,'Delta 13 C (o/oo)'] = test.loc[:,'Delta 13 C (o/oo)'].fillna(train.loc[:,'Delta 13 C (o/oo)'].mean())\n",
    "\n",
    "\n",
    "#test[test.isna().sum(axis=1) > 0]\n",
    "test.info() # 결측값 더이상 없음 확인 -> rangeidx 228 = 모든 요소 228 non-null으로 확인됨."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5e6882-097e-420a-96e6-d866fcdb559c",
   "metadata": {},
   "source": [
    "단순히 최빈값으로 결측값을 처리하는것보다 더 좋은 처리방안이 존재하는데\n",
    "다른 변수와의 연관관계를 생각하여 처리하는 방법이다.\n",
    "\n",
    "하지만 EDA방법론의 부족탓인지 직관적으로 떠오르지 않아.(5변수 중에 완전히 범주가 갈리는 변수는 존재하지 않기 때문) KNN-imputer를 통해 유사한 값을 탐색, 대체하는 모듈을 사용해 처리를 진행하였다.\n",
    "\n",
    "먼저 KNN-imputer는 모든 입력을 수치형으로 받는다. 따라서 라벨 인코딩을 수동으로 실시하여 주었다.\n",
    "(NA값을 na값으로 두는 인코딩이 필요하기에 labelencoder를 사용하지 않았다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba0310b5-de3c-429c-81bd-0aadb00e8791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 명목형 변수는 수치형 라벨로 코딩필요. 이 경우 mapping을 이용한 값의 처리, NA값은 NA로만 표기 되었으므로, 변경할 필요가 없음.\n",
    "# 라벨 코딩을 위해 아래 파악은 필수.\n",
    "train['Species'].value_counts()\n",
    "train['Island'].value_counts()\n",
    "train['Clutch Completion'].value_counts()\n",
    "train['Sex'].value_counts()\n",
    "\n",
    "# train셋과 test셋의 가지는 명목형 변수의 범주는 아래와 같이 동일하다.\n",
    "idx_species = {'Gentoo penguin (Pygoscelis papua)' : 0, 'Adelie Penguin (Pygoscelis adeliae)' : 1,  'Chinstrap penguin (Pygoscelis antarctica)' : 2}\n",
    "idx_island = {'Biscoe' : 0, 'Dream' : 1, 'Torgersen' : 2}\n",
    "idx_clutch = {'Yes' : 0, 'No' : 1}\n",
    "idx_sex = {'MALE' : 0, 'FEMALE' : 1}\n",
    "\n",
    "# 라벨링과정 실시, NA를 살려야하기 때문에 labelencoder를 사용하지 않았다.\n",
    "train['Species'] = train['Species'].map(idx_species)\n",
    "train['Island'] = train['Island'].map(idx_island)\n",
    "train['Clutch Completion'] = train['Clutch Completion'].map(idx_clutch)\n",
    "train['Sex'] = train['Sex'].map(idx_sex)\n",
    "\n",
    "# test셋에 대해서도 동등하게 매핑 실시.\n",
    "test['Species'] = test['Species'].map(idx_species)\n",
    "test['Island'] = test['Island'].map(idx_island)\n",
    "test['Clutch Completion'] = test['Clutch Completion'].map(idx_clutch)\n",
    "test['Sex'] = test['Sex'].map(idx_sex)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001ad7c9-0f1b-419c-b43c-e53aa5f4f268",
   "metadata": {},
   "source": [
    "이렇게 범주형 변수들에 대해 매핑을 통한 라벨 인코딩을 실시한 뒤\n",
    "KNNImputer를 사용하여 Sex 열에 대한 결측값 처리를 진행하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae6cf3db-f6f1-460c-9194-5e79b2006292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN을 Sex행에 대해 적용해보자.\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors = 1) \n",
    "# KNN 기준 n_neighbors = 이웃 파라미터, 디폴트값이 5임. \n",
    "# 예를들어 5를 쓰는데 Na값의 이웃으로 해당값과 유사한, 0,0,0,1,1 이라는 Sex의 이웃 KNN에 포함될경우 이들의 평균인 0.4로 예측하게 된다.\n",
    "# 따라서 우리는 가장 비슷한 예제로 채우고 싶기 때문에 n_neighbor = 1을 사용하였다.\n",
    "# 만약 큰 숫자를 사용한다면 시그모이드 같은 함수를 써서 분류를 해야하는 상황이 올지 확신이 서지는 않는다.\n",
    "\n",
    "# 지금 조심해야 하는게, train셋은 Bodymass(예측해야 할 값) 포함되어 있음. 따라서 bodymass는 KNN과정에 포함되면 안됨.\n",
    "# 따로 적용하자.\n",
    "temp = train.drop('Body Mass (g)',axis=1)\n",
    "temp_y = train.loc[:,'Body Mass (g)']\n",
    "\n",
    "# KNN은 temp에 대해 실행하고, 아래 전처리 작업에 일관성을 위해 다시 train셋에 합처주겠다.\n",
    "temp = pd.DataFrame(imputer.fit_transform(temp), columns = temp.columns)\n",
    "train = pd.concat([temp, temp_y], axis=1)\n",
    "\n",
    "# test에는 따로 body mass가 존재하지 않으니 빼면 좋지.\n",
    "test = pd.DataFrame(imputer.transform(test), columns = test.columns)\n",
    "\n",
    "# temp는 지워준다.\n",
    "del temp; del temp_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec5a911-7792-480e-a58e-ef5ba9efc39b",
   "metadata": {},
   "source": [
    "## Scaling파트\n",
    "\n",
    "명목형 변수는 labelencoding을 통해 분석에 사용할 수 있지만, onehotencoding보다 떨어지는 성능을 발휘하곤 한다. 따라서, 해당행에 대해 onehotEncoding과 StandardScaling을 통한 통합 스케일러를 제작하였다.\n",
    "\n",
    "또한 train셋에 X값과, y값이 같이 존재하므로 이 단계에서 분리시켜 주도록 하겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11d84017-356c-43f1-8ea5-c9be2cbf8327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ColumnTransformer()라는 좋은 수단이 있음.\n",
    "# 범주형과 수치형의 작업을 동시에 할 수 있는 메소드. \n",
    "# OneHot + 표준화.\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "OneHotScaleing = OneHotEncoder(drop='first') # drop = 'first'로 첫행 버림으로서, 자유도? 제공함.\n",
    "StandardScaleing = StandardScaler()\n",
    "\n",
    "ColumnScaleing = ColumnTransformer([\n",
    "    (\"onehot\", OneHotScaleing, ['Species', 'Island', 'Clutch Completion', 'Sex']),\n",
    "    (\"scaling\", StandardScaleing, ['Culmen Length (mm)', 'Culmen Depth (mm)','Flipper Length (mm)','Delta 15 N (o/oo)','Delta 13 C (o/oo)'])\n",
    "])\n",
    "# 스케일링 결과는 행 불러온 순서대로 정해진다.\n",
    "\n",
    "# 파이프라인 이용하면 되니, 데이터셋의 형태만 올바르게 해주자.\n",
    "train_X = train.drop('Body Mass (g)',axis=1)\n",
    "\n",
    "# y값은  따로 스케일링을 진행해준다 => 원상복구할때 이 형태가 편함.\n",
    "y_scaling = StandardScaler()\n",
    "train_y = np.array(train.loc[:,'Body Mass (g)']).reshape(-1,1)\n",
    "train_y_transform = y_scaling.fit_transform(train_y)\n",
    "\n",
    "# test셋에 대해서도 동등한 처리를 하여주자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d59f4cc-a4a5-4f91-9c7e-88ecb6c55f58",
   "metadata": {},
   "source": [
    "혹시 모를 onehot+정규형에 대한 스케일러 또한 제작해 주었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "821ae624-587b-4854-b300-2b29704d9588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHot + 정규화.\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "OneHotScaleing2 = OneHotEncoder(drop='first') # drop = 'first'로 첫행 버림으로서, 자유도? 제공함.\n",
    "MinMaxScaleing2 = MinMaxScaler()\n",
    "\n",
    "ColumnScaleing2 = ColumnTransformer([\n",
    "    (\"onehot\", OneHotScaleing2, ['Species', 'Island', 'Clutch Completion', 'Sex']),\n",
    "    (\"scaling\", MinMaxScaleing2, ['Culmen Length (mm)', 'Culmen Depth (mm)','Flipper Length (mm)','Delta 15 N (o/oo)','Delta 13 C (o/oo)'])\n",
    "])\n",
    "# 스케일링 결과는 행 불러온 순서대로 정해진다.\n",
    "\n",
    "# 파이프라인 이용하면 되니, 데이터셋의 형태만 올바르게 해주자.\n",
    "train_X = train.drop('Body Mass (g)',axis=1)\n",
    "\n",
    "# y값은  따로 스케일링을 진행해준다 => 원상복구할때 이 형태가 편함.\n",
    "y_scaling_minmax = MinMaxScaler()\n",
    "train_y = np.array(train.loc[:,'Body Mass (g)']).reshape(-1,1)\n",
    "train_y_transform_minmax = y_scaling_minmax.fit_transform(train_y)\n",
    "\n",
    "# test셋에 대해서도 동등한 처리를 하여주자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19d8643-57fc-4521-b257-b7e2abda3e55",
   "metadata": {},
   "source": [
    "## 데이터셋 분리\n",
    "\n",
    "train, valid, test셋으로 분리시켜 주었다.\n",
    "\n",
    "test셋은 주어진 자료가 존재하므로, train셋을 train과 valid 두 종류로 나눠 검정을 진행하도록 하였다.\n",
    "아래 코드에서 결과의 통일성을 위해 임으로 seed를 고정시켜 사용하였다.\n",
    "시드를 고정하지 않은 방법과, 차이가 큰 편이다(현 예제는 상당히 좋은 결과를 내고 있지만, 시드 사용하지 않고는 valid에게 82~86%성능을 보이기도 한다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dd2e275-62a7-4707-9f68-bb74f7a25b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 상당히 데이터 세트가 적다.(114개의 훈련 레이블 -> 0.8, 0.2비율로 나누는게 적절하지 않을까? 큰 샘플이면 더 작아져아하지만...)\n",
    "# train_test_split에서 따로 층화표집 필요성이 존재하지 않는다. 회귀니까. => 전처리 끝.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_X, train_y_transform, test_size=0.2, random_state = 404324)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cb33b6-4783-43ee-97c9-3939ccc755f1",
   "metadata": {},
   "source": [
    "대충 생각나는 모델 -> 랜덤포레스트 회귀, XGBOOST 회귀, 결정나무 회귀 등.\n",
    "선형회귀, 라소릿지. XGBOOST만 해보자.\n",
    "\n",
    "자료 특징 - 라벨 인코딩 되어있음. 원핫 인코딩은 안됨. 명목형 4개, 수치형 5개, 예측은 수치형(회귀)\n",
    "k-mean 회귀는 변수 적을때 유용(2-3변수) 제외. -> 적을땐 선형회귀보다 유용. 변수개수 증가시 MSE가 선형회귀보다 크게 증가.\n",
    "\n",
    "## 선형회귀분석(linear_reg방법, 정규방정식 이용 회귀)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6e3b23f-3755-409d-8225-2a3ca0bb6def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train셋의 결정계수 : 0.864235213143689\n",
      "valid셋의 결정계수 : 0.8721632069900896\n",
      "valid셋의 표준화된 MSE : 0.11186820226633716\n",
      "valid셋의 MSE : 67769.51010156046\n",
      "valid셋의 RMSE : 260.3257768672946\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline # pipeline = 튜플(제목+모듈)로 입력, make_pipeline은 튜플 쓸 필요가 없는 파이프라인.\n",
    "from sklearn.linear_model import LinearRegression # 선형 회귀 모델\n",
    "\n",
    "\n",
    "linear_model = Pipeline([\n",
    "    ('scaleing', ColumnScaleing),\n",
    "    ('linearReg', LinearRegression())\n",
    "])\n",
    "# 스케일러에 의해서 자동으로 정리됨.\n",
    "\n",
    "# 모델 훈련\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "# 모델 예측\n",
    "linear_model.predict(X_valid)\n",
    "\n",
    "# 모델 score(회귀-결정계수) -> 아래 r2_score와 동일한 실행결과를 갖는다.\n",
    "linear_model.score(X_train, y_train)\n",
    "linear_model.score(X_valid, y_valid)\n",
    "\n",
    "# 결정계수 맞는지 따로 확인.\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "y_train_pred = linear_model.predict(X_train)\n",
    "y_valid_pred = linear_model.predict(X_valid).reshape(-1,1)\n",
    "\n",
    "print(f'train셋의 결정계수 : {r2_score(y_train, y_train_pred)}')\n",
    "print(f'valid셋의 결정계수 : {r2_score(y_valid, y_valid_pred)}')\n",
    "\n",
    "# mse가 궁금한가?\n",
    "print(f'valid셋의 표준화된 MSE : {mean_squared_error(y_valid, y_valid_pred)}')\n",
    "print(f'valid셋의 MSE : {mean_squared_error(y_scaling.inverse_transform(y_valid), y_scaling.inverse_transform(y_valid_pred))}')\n",
    "\n",
    "# RMSE 구해보기.\n",
    "import math\n",
    "print(f'valid셋의 RMSE : {math.sqrt(mean_squared_error(y_scaling.inverse_transform(y_valid), y_scaling.inverse_transform(y_valid_pred)))}')\n",
    "\n",
    "# 테스트셋에 대해서 예측한다면 이렇게 된다.\n",
    "test_pred = linear_model.predict(test)\n",
    "\n",
    "# 다시 원래대로 돌려준다면? 이렇게 된다.\n",
    "linear_test_pred = y_scaling.inverse_transform(test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecee061b-8f93-4dfa-b904-49d55730bf36",
   "metadata": {},
   "source": [
    "선형회귀에 그리드 서치는 불가능 => 목표함수가 정해져 있기 때문에\n",
    "회귀분석에서. 식 자체에서 지정할 수 있는 모수 없음 MLE에 의해 b = (t(X)X)^-1 * t(x)y로 구해진다.\n",
    "\n",
    "\n",
    "# SGDRegressor를 활용한 선형회귀분석(확률적 경사하강법)\n",
    "linear_model과 차이점은 확률적 경사하강법을 사용하기 때문에 파라미터 조정이 가능한것이 큰 특징이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0072f02-f71b-4966-84bc-beefcf8aad87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train셋의 결정계수 : 0.8115678666963199\n",
      "valid셋의 결정계수 : 0.8638145230410679\n",
      "valid셋의 표준화된 MSE : 0.11917401965018284\n",
      "valid셋의 MSE : 72195.35815278704\n",
      "valid셋의 RMSE : 268.69193912878563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\styli\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# sgdRegressor = 회귀분석과 동일하지만, 경사하강법을 이용하는것이 특징. 하이퍼파라미터가 존재함.\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "SGD_model = Pipeline([\n",
    "    ('scaleing', ColumnScaleing),\n",
    "    ('SGD_reg', SGDRegressor())\n",
    "])\n",
    "\n",
    "# 모델 훈련\n",
    "SGD_model.fit(X_train, y_train)\n",
    "\n",
    "# 모델 예측\n",
    "SGD_model.predict(X_valid)\n",
    "\n",
    "# 모델 score(회귀-결정계수)\n",
    "print(f'train셋의 결정계수 : {SGD_model.score(X_train, y_train)}')\n",
    "print(f'valid셋의 결정계수 : {SGD_model.score(X_valid, y_valid)}')\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "y_train_pred = SGD_model.predict(X_train)\n",
    "y_valid_pred = SGD_model.predict(X_valid).reshape(-1,1)\n",
    "\n",
    "# mse 체크\n",
    "print(f'valid셋의 표준화된 MSE : {mean_squared_error(y_valid, y_valid_pred)}')\n",
    "print(f'valid셋의 MSE : {mean_squared_error(y_scaling.inverse_transform(y_valid), y_scaling.inverse_transform(y_valid_pred))}')\n",
    "\n",
    "# RMSE 구해보기.\n",
    "import math\n",
    "print(f'valid셋의 RMSE : {math.sqrt(mean_squared_error(y_scaling.inverse_transform(y_valid), y_scaling.inverse_transform(y_valid_pred)))}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e7e48e-5d22-472d-bfa4-b21a402c69d9",
   "metadata": {},
   "source": [
    "SGD_regressor의 grid search를 활용한 성능 향상 시도.\n",
    "\n",
    "임의의 모수를 통해 성능을 향상시키고자 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3b547b5-06cd-4e37-97d6-3f22cf9f49e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적의 하이퍼 파라미터 : {'SGD_reg__epsilon': 0.01, 'SGD_reg__eta0': 0.05, 'SGD_reg__learning_rate': 'adaptive', 'SGD_reg__loss': 'epsilon_insensitive'}\n",
      "최적의 모델 평균 성능 : -0.4092604859591821\n",
      "grid-search로 구한 valid셋의 결정계수 : 0.8927187524809435\n",
      "valid셋의 RMSE : 238.47955193485896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\styli\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# GRID_SEARCH (SGD-선형회귀는 파라미터 지정 가능.)\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle = True) # shuffle=True로 매 k-fold의 편향을 없애준다. 층화가 필요하면 StratifiedKFold 사용할것.\n",
    "params = {'SGD_reg__loss' : ['squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "          'SGD_reg__learning_rate' : ['optimal','invscaling','adaptive'],\n",
    "          'SGD_reg__eta0' : [0.05, 0.01, 0.001],\n",
    "          'SGD_reg__epsilon' : [0.01, 0.05, 0.1, 0.2]\n",
    "}\n",
    "# max_iter나 tol(=eps)는 최초 파이프라인에서 선정하면 더 좋을것으로 생각.\n",
    "# panelty항과 여러 변수를 조정하면, SGDRegressor는 lasso 혹은 elasticnet도 연산 가능합니다.\n",
    "# fit_interceptbool = 절편이 있는지 없는지.\n",
    "# 'learning_ratestring' = default값은 'invscaling': eta = eta0 / pow(t, power_t)\n",
    "# epsilonfloat, default=0.1 'huber', 'epsilon_insensitive'또는 'squared_epsilon_insensitive'인 경우에만 해당됩니다 \n",
    "# 'huber'의 경우 예측을 정확하게 얻는 것이 덜 중요 해지는 임계 값을 결정합니다\n",
    "# 내 임의대로 배치한거임. 훈련결과 확인후 지속적인 조정 필요.\n",
    "\n",
    "grid = GridSearchCV(estimator= SGD_model, param_grid = params, scoring= 'neg_root_mean_squared_error', cv = kfold, n_jobs=-1)\n",
    "# grid.get_params().keys() 통해 키 이름 파악할것. Pipeline이라서 기본 변수명과 다름.\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# 최적의 Grid Search 파라미터.\n",
    "print(f'최적의 하이퍼 파라미터 : {grid.best_params_}'); print(f'최적의 모델 평균 성능 : {grid.best_score_}')\n",
    "\n",
    "# 그리드 서치 된 결과, 결정계수.\n",
    "new_pred = grid.predict(X_valid).reshape(-1,1)\n",
    "print(f'grid-search로 구한 valid셋의 결정계수 : {r2_score(y_valid, new_pred)}')\n",
    "\n",
    "\n",
    "print(f'valid셋의 RMSE : {math.sqrt(mean_squared_error(y_scaling.inverse_transform(y_valid), y_scaling.inverse_transform(new_pred)))}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a504863-b1ac-43d3-8421-8343f5cf3a60",
   "metadata": {},
   "source": [
    "# 추가로 탐구할 거리들\n",
    "쉽게 설명하면 lasso, ridge를 가중평균을 통해 구한값이 ElasticNet이 된다. -> 실제로는 그냥 penalty항이 다른것입니다.\n",
    "현재로선 선형회귀 이상 진행하지 않았습니다.\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "\n",
    "\n",
    "# XGBOOST를 활용한 회귀.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5de3687-886d-4e9c-b34e-0da805ff8a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaleing',\n",
       "                 ColumnTransformer(transformers=[('onehot',\n",
       "                                                  OneHotEncoder(drop='first'),\n",
       "                                                  ['Species', 'Island',\n",
       "                                                   'Clutch Completion',\n",
       "                                                   'Sex']),\n",
       "                                                 ('scaling', StandardScaler(),\n",
       "                                                  ['Culmen Length (mm)',\n",
       "                                                   'Culmen Depth (mm)',\n",
       "                                                   'Flipper Length (mm)',\n",
       "                                                   'Delta 15 N (o/oo)',\n",
       "                                                   'Delta 13 C (o/oo)'])])),\n",
       "                ('XGB_Reg',\n",
       "                 XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                              colsample_bylevel=1, cols...\n",
       "                              gamma=0, gpu_id=-1, importance_type=None,\n",
       "                              interaction_constraints='',\n",
       "                              learning_rate=0.300000012, max_delta_step=0,\n",
       "                              max_depth=6, min_child_weight=1, missing=nan,\n",
       "                              monotone_constraints='()', n_estimators=100,\n",
       "                              n_jobs=4, num_parallel_tree=1, predictor='auto',\n",
       "                              random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                              scale_pos_weight=1, subsample=1,\n",
       "                              tree_method='exact', validate_parameters=1,\n",
       "                              verbosity=None))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import explained_variance_score\n",
    "\n",
    "# xgboost.XGBRegressor(n_estimators=100, learning_rate=0.08, gamma=0, subsample=0.75, colsample_bytree=1, max_depth=7)\n",
    "xgb_model = Pipeline([\n",
    "    ('scaleing', ColumnScaleing),\n",
    "    ('XGB_Reg', XGBRegressor())\n",
    "])\n",
    "\n",
    "\n",
    "xgb_model.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74ad3158-85de-42bf-a159-18c11ee15d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Feature importance'}, xlabel='F score', ylabel='Features'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xgboost.plot_importance(xgb_model[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc45724-063f-494d-ab53-55d8d1514eaa",
   "metadata": {},
   "source": [
    "xgb모델의 특징인, xgb 모델의 중요변수 그래프를 표시 가능하다.\n",
    "\n",
    "일반적인 사용법은\n",
    "xgboost.plot_importance(xgb_model)이지만,\n",
    "현재 모델은 파이프라인으로 사용중이기에 해당 방법 xgb_model위치를 지정받아야 그릴 수 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "423def4b-9e7d-4926-90f9-b9840b7c4a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train셋의 결정계수 : 0.9999989222489813\n",
      "valid셋의 결정계수 : 0.8030914165845888\n",
      "valid셋의 결정계수_r2_score로 확인. : 0.8030914165845888\n",
      "valid셋의 표준화된 MSE. : 0.17231196683560004\n",
      "valid셋의 MSE. : 104386.20686103209\n",
      "valid셋의 RMSE. : 323.0885433763198\n",
      "valid셋의 분산 설명비율. : 0.8009183420470298\n"
     ]
    }
   ],
   "source": [
    "# 결정계수 확인.\n",
    "print(f'train셋의 결정계수 : {xgb_model.score(X_train, y_train)}')\n",
    "print(f'valid셋의 결정계수 : {xgb_model.score(X_valid, y_valid)}')\n",
    "\n",
    "\n",
    "# 결정계수 맞는지 따로 확인. mse, 설명분산비율 확인.\n",
    "from sklearn.metrics import r2_score, mean_squared_error, explained_variance_score\n",
    "y_valid_pred = xgb_model.predict(X_valid).reshape(-1,1)\n",
    "\n",
    "print(f'valid셋의 결정계수_r2_score로 확인. : {r2_score(y_valid, y_valid_pred)}')\n",
    "print(f'valid셋의 표준화된 MSE. : {mean_squared_error(y_valid, y_valid_pred)}')\n",
    "print(f'valid셋의 MSE. : {mean_squared_error(y_scaling.inverse_transform(y_valid), y_scaling.inverse_transform(y_valid_pred))}')\n",
    "print(f'valid셋의 RMSE. : {math.sqrt(mean_squared_error(y_scaling.inverse_transform(y_valid), y_scaling.inverse_transform(y_valid_pred)))}')\n",
    "print(f'valid셋의 분산 설명비율. : {explained_variance_score(y_valid_pred,y_valid)}')\n",
    "\n",
    "\n",
    "# 테스트셋에 대해서 예측한다면 이렇게 된다.\n",
    "test_pred = xgb_model.predict(test).reshape(-1,1)\n",
    "\n",
    "# 다시 원래대로 돌려준다면? 이렇게 된다.\n",
    "# y_scaling.inverse_transform(test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905f60ec-f4d8-4104-aa44-713306bb8fb7",
   "metadata": {},
   "source": [
    "과적합이 된것으로 보인다.\n",
    "테스트셋의 결정계수에 비해 valid셋의 결정계수가 작은것을 확인\n",
    "RMSE가 선형모델보다 크게 나오는 경향을 보이고 있다.\n",
    "gridsearch를 통해 모델의 향상을 시도해 보겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0de2579d-af86-416a-a1a0-65a48d5c402f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적의 하이퍼 파라미터 : {'XGB_Reg__colsample_bytree': 0.8, 'XGB_Reg__gamma': 1, 'XGB_Reg__learning_rate': 0.1, 'XGB_Reg__max_depth': 3, 'XGB_Reg__n_estimators': 200, 'XGB_Reg__subsample': 0.5}\n",
      "최적의 모델 평균 성능 : -0.4321185965333039\n",
      "valid셋의 결정계수. : 0.8659422190242869\n",
      "valid셋의 MSE. : 71067.40545786722\n",
      "valid셋의 RMSE. : 266.5847059714177\n"
     ]
    }
   ],
   "source": [
    "# GridSearch 해보자.\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle = True) # shuffle=True로 매 k-fold의 편향을 없애준다. 층화가 필요하면 StratifiedKFold 사용할것.\n",
    "params = {\n",
    "         'XGB_Reg__learning_rate': [0.5, 0.2, 0.1, 0.05], #so called `eta` value  \n",
    "         'XGB_Reg__max_depth': [2, 3, 4],\n",
    "         'XGB_Reg__gamma': [0.1, 0.5, 1],\n",
    "         'XGB_Reg__subsample': [0.5, 0.6, 0.7],\n",
    "         'XGB_Reg__colsample_bytree': [0.6, 0.8, 1.0],\n",
    "         'XGB_Reg__n_estimators': [10,50,100,200]\n",
    "}\n",
    "# 내 임의대로 배치한거임. 아래 기준보고 계속 조정 필요.\n",
    "\n",
    "grid = GridSearchCV(estimator= xgb_model, param_grid = params, scoring= 'neg_root_mean_squared_error', cv = kfold, n_jobs=4)\n",
    "# n_jobs = 작업 cpu개수-> 4코어 노트북에서 작업함. verbose - 작업 상황 표시\n",
    "# cv=k-fold 개수. 매개변수 이용위해 따로 지정하였음. scoring = 여러 변수 참조. 사실 잘 모르겠음. mse, mae, acc, r2 등등 있는데 종류 잘 모름.\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "# 훈련이 안되는 에러를 발견했는데 =>  Check the list of available parameters with `estimator.get_params().keys()`. 에러.\n",
    "# grid.get_params().keys()해서 나오는 변수가 params가 된다. pipeline을 사용하면서 변화한 변수명이 문제임.\n",
    "# estimator__XGB_Reg__n_estimators로 나왔다면 'estimator__' 부분은 떼고 'XGB_Reg__n_estimators'만 사용.\n",
    "\n",
    "print(f'최적의 하이퍼 파라미터 : {grid.best_params_}'); print(f'최적의 모델 평균 성능 : {grid.best_score_}')\n",
    "\n",
    "# 그리드 서치 된 결과, 결정계수.\n",
    "npred = grid.predict(X_valid).reshape(-1,1)\n",
    "print(f'valid셋의 결정계수. : {r2_score(y_valid, npred)}')\n",
    "print(f'valid셋의 MSE. : {mean_squared_error(y_scaling.inverse_transform(y_valid), y_scaling.inverse_transform(npred))}')\n",
    "print(f'valid셋의 RMSE. : {math.sqrt(mean_squared_error(y_scaling.inverse_transform(y_valid), y_scaling.inverse_transform(npred)))}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606d865d-92ae-4a16-b600-01d5606024c3",
   "metadata": {},
   "source": [
    "파라미터 조정을 세부적으로 해보지 못했지만, 개선이 잘 이뤄지지 않았다.(선형회귀만큼 감소하지는 못함)\n",
    "최초 모델선정시 성능이 우수한 모델을 대상으로 파라미터 조정을 시도하는것이 올바르겠다는 판단을 하게 되었다.\n",
    "\n",
    "# 그외 찾아볼만한, 부스팅 모델\n",
    "from catboost import CatBoostRegressor\n",
    "-> 자체적으로 시계열을 형성함. 범주형이 많을때 유효한 성능 등장, 결측이 있으면 민감하게 반응.\n",
    "-> 하이퍼파라미터 조정이 불필요한편\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bdc54f8f-fc93-4619-b374-481ff03fe11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train셋의 스코어 : -179.30022114691397\n",
      "valid셋의 스코어 : -44.74107485860086\n",
      "train셋의 결정계수 : 0.9988598271554997\n",
      "valid셋의 결정계수 : 0.7877608333707691\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "cat_model = Pipeline([\n",
    "    ('scaleing', ColumnScaleing),\n",
    "    ('XGB_Reg', CatBoostRegressor(verbose=0))\n",
    "])\n",
    "\n",
    "cat_model.fit(X_train,y_train)\n",
    "\n",
    "train_pred = cat_model.predict(X_train).reshape(-1,1)\n",
    "val_pred = cat_model.predict(X_valid).reshape(-1,1)\n",
    "\n",
    "# score check\n",
    "print(f'train셋의 스코어 : {cat_model.score(X_train, y_train)}')\n",
    "print(f'valid셋의 스코어 : {cat_model.score(X_valid, y_valid)}')\n",
    "# r2_score로 다시체크\n",
    "print(f'train셋의 결정계수 : {r2_score(y_train, train_pred)}')\n",
    "print(f'valid셋의 결정계수 : {r2_score(y_valid, val_pred)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282900ee-6bf7-4f38-9980-e15dc49dfdef",
   "metadata": {},
   "source": [
    "XGBoost와 동일하게 train셋에 과적합 발생으로 valid셋에 대해 추정을 못하는 결과를 나타내는것을 확인하였습니다.\n",
    "catboost는 파라미터 조정이 약간 무의미한 경향도 존재하여 향상 가능성이 낮아 진행하지 않았습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3a15fb-2003-441b-8c59-b948010a6559",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 그외 찾아볼만한, 부스팅 모델\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "\n",
    "시간이 오래걸리는데 RandomizedSearchCV를 쓰는건 어떨까? 그리드서치와 유사한 성능을 보이는것으로 알려져 있으며, 사용법을 공부해 보는것이 좋아보인다.\n",
    "\n",
    "# 랜덤 포레스트 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6c3379c-cca5-4397-9936-8999539eec84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid셋의 결정계수. : 0.8529335154157139\n",
      "valid셋의 표준화된 MSE. : 0.1286958383162713\n",
      "valid셋의 MSE. : 77963.65489130432\n",
      "valid셋의 RMSE. : 279.2197251114332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\styli\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:394: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "rforest_model = Pipeline([\n",
    "    ('scaleing', ColumnScaleing),\n",
    "    ('rforest_Reg', RandomForestRegressor())\n",
    "])\n",
    "\n",
    "\n",
    "rforest_model.fit(X_train,y_train)\n",
    "\n",
    "# 결정계수 확인.\n",
    "rforest_model.score(X_train, y_train)\n",
    "rforest_model.score(X_valid, y_valid)\n",
    "\n",
    "# 결정계수 맞는지 따로 확인. mse, 설명분산비율 확인.\n",
    "from sklearn.metrics import r2_score, mean_squared_error, explained_variance_score\n",
    "y_valid_pred = rforest_model.predict(X_valid).reshape(-1,1)\n",
    "\n",
    "print(f'valid셋의 결정계수. : {r2_score(y_valid, y_valid_pred)}')\n",
    "print(f'valid셋의 표준화된 MSE. : {mean_squared_error(y_valid, y_valid_pred)}')\n",
    "print(f'valid셋의 MSE. : {mean_squared_error(y_scaling.inverse_transform(y_valid), y_scaling.inverse_transform(y_valid_pred))}')\n",
    "print(f'valid셋의 RMSE. : {math.sqrt(mean_squared_error(y_scaling.inverse_transform(y_valid), y_scaling.inverse_transform(y_valid_pred)))}')\n",
    "\n",
    "mean_squared_error(y_valid, y_valid_pred)\n",
    "explained_variance_score(y_valid_pred,y_valid) # R^2과 같다고 알려져 있지만, 다름. 왜?\n",
    "\n",
    "# 테스트셋에 대해서 예측한다면 이렇게 된다.\n",
    "test_pred = rforest_model.predict(test).reshape(-1, 1)\n",
    "\n",
    "# 다시 원래대로 돌려준다면? 이렇게 된다.\n",
    "# y_scaling.inverse_transform(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c7490c3-2e4b-4957-9876-7568b4c807f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적의 하이퍼 파라미터 : {'XGB_Reg__colsample_bytree': 0.8, 'XGB_Reg__gamma': 1, 'XGB_Reg__learning_rate': 0.1, 'XGB_Reg__max_depth': 3, 'XGB_Reg__n_estimators': 200, 'XGB_Reg__subsample': 0.5}\n",
      "최적의 모델 평균 성능 : -0.4321185965333039\n",
      "valid셋의 결정계수. : 0.8559432277389246\n",
      "valid셋의 MSE. : 76368.13043478261\n",
      "valid셋의 RMSE. : 276.34784318822284\n"
     ]
    }
   ],
   "source": [
    "# grid_search\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle = True) # shuffle=True로 매 k-fold의 편향을 없애준다. 층화가 필요하면 StratifiedKFold 사용할것.\n",
    "params = { 'rforest_Reg__n_estimators' : [10, 50,100],\n",
    "           'rforest_Reg__max_depth' : [6, 12, 18, 24],\n",
    "           'rforest_Reg__min_samples_leaf' : [1, 6, 12, 18],\n",
    "           'rforest_Reg__min_samples_split' : [2, 8, 16, 20]\n",
    "            }\n",
    "grid2 = GridSearchCV(estimator= rforest_model, param_grid = params, scoring= 'neg_root_mean_squared_error', cv = kfold, n_jobs=4)\n",
    "\n",
    "grid2.fit(X_train, np.ravel(y_train))\n",
    "# 너는 왜 np.ravel 써야하는지 잘 모르겠음. => 1차원 변환 함수. reshape(-1,1)는 통하지 않음.\n",
    "# XGboost에서는 np (변수수,1)형으로 넣으면 따로 요구하지도 않았는데? 얘는 따로 평탄화도 해야함.\n",
    "# 안쓰면 A column-vector y was passed when a 1d array was expected 에러 등장함.\n",
    "\n",
    "print(f'최적의 하이퍼 파라미터 : {grid.best_params_}'); print(f'최적의 모델 평균 성능 : {grid.best_score_}')\n",
    "\n",
    "# 그리드 서치 된 결과, 결정계수.\n",
    "npred = grid2.predict(X_valid).reshape(-1, 1)\n",
    "print(f'valid셋의 결정계수. : {r2_score(y_valid, npred)}')\n",
    "print(f'valid셋의 MSE. : {mean_squared_error(y_scaling.inverse_transform(y_valid), y_scaling.inverse_transform(npred))}')\n",
    "print(f'valid셋의 RMSE. : {math.sqrt(mean_squared_error(y_scaling.inverse_transform(y_valid), y_scaling.inverse_transform(npred)))}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567892bb-7493-44fc-8889-b6f445de5316",
   "metadata": {},
   "source": [
    "특이하게도, 해당 데이터셋에는 선형모델이 가장 우수한 성능을 보이고 있다.\n",
    "다양하게 시드를 바꿔서 시도해 보고 일관적인 결과를 보이는지 테스트해볼 필요성이 있을것 같다.\n",
    "\n",
    "\n",
    "뭔가 더 해보고 싶은 모듈들.\n",
    "\n",
    "앙상블 모델.(나무 기반.)\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "이 두개의 모듈을 더 사용해 보고 싶다는 생각을 해보았다.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
